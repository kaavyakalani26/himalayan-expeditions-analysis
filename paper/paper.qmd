---
title: "Understanding Factors Contributing to a Successful Himalayan Expedition"
subtitle: "Analysis using data from Himalayan expeditions from 1905 through Spring 2019 leveraging Bayesian Logistic Regression"
author: Kaavya Kalani
thanks: "Code and data supporting this analysis is available at: [https://github.com/kaavyakalani26/himalayan-expeditions-analysis](https://github.com/kaavyakalani26/himalayan-expeditions-analysis)"
date: today
date-format: long
abstract: "This study analyses the relationship between different demographic, environmental and geographic factors and the successfulness of an attempt to summit a peak. Data from Himalayan expeditions in Nepal from 1905 through Spring 2019 is used and a Bayesian Logistic Regression model is leveraged to analyse the trends and factors influencing a successful summit. I find a strong relation between height of the peak, sex, age, season of expedition, if it was a solo ascent, and the success in summitting. Young age, being a man and embarking on the expedition in Spring or Autumn are some factors which increase one's chances of having a successful summit. The insights from this study aim to help future expedition planning, risk management, and safety protocols."
format: pdf
number-sections: true
toc: true
bibliography: references.bib
---

```{r}
#| include: false
#| warning: false
#| message: false

library(broom.mixed)
library(tidyverse)
library(dplyr)
library(knitr)
library(ggplot2)
library(modelsummary)
library(here)
library(kableExtra)
library(arrow)

expeditions_model <- readRDS(here("models/single_bay.rds"))
analysis_data <- read_parquet(here("data/analysis_data/expeditions.parquet"))
predictions <- read.csv(here("data/predictions/predictions.csv"))
```

# Introduction
Mountaineering, with its blend of adventure and challenge, has captivated explorers for generations. It represents a pinnacle of human endeavor, testing physical prowess, mental fortitude, and strategic planning against some of the most formidable natural landscapes on Earth. Amidst the allure of conquering these majestic peaks, lies a critical question: what factors contribute to the likelihood of a successful summit attempt? This paper delves into precisely this inquiry.

There are numerous mountain ranges around the world where people embark on expeditions. One of the most famous mountain ranges are the Himalayas, which also consist of the highest mountain peak in the world, Mt. Everest. My paper uses the data from expeditions to the Himalayan mountain ranges in Nepal.

My estimand is the relationship between different demographic, environmental and geographic factors (such as height of the peak, sex, age, season of expedition and if it was a solo ascent) and the successfulness of climbing a summit. Using the analysis dataset, my goal is to identify trends and factors that influence a successful expedition and eventually conclude what factors help in a more successful attempt.

I use data from Alex Cooksonâ€™s datasets (link) which are sourced from The Himalayan Expedition records (link), to understand these factors and trends. This is done by leveraging a Bayesian Logistic Regression model and then predicting the probability of a successful attempt over various demographic and environmental factors.

My analysis shows how mountaineering is a highly male dominated activity. It highlights that young age, being a man and embarking on the expedition in Spring or Autumn are some factors which increase one's chances of having a successful summit. 

The findings highlighted by this research have practical implications for expedition planning, risk management, and safety protocols. Ultimately, the study aims to improve decision-making in high-altitude mountaineering, making it safer and more informed in one of the world's most challenging environments.

The paper is further organized into four sections. @sec-data discusses how the dataset to be used for the analysis was obtained and pre-processed. I will explain the variables of interest in the dataset used for the analysis. @sec-model describes the model being used for the analysis. @sec-results then highlights and discusses the trends and associations found during the analysis. Lastly, @sec-discussion talks about some interesting trends found in @sec-results in depth, link it to the real world and also highlight the weaknesses and future of my analysis.

# Data {#sec-data}
For this analysis, I have combined three datasets into one, which is used for analysis. The datasets were cleaned and analysed using the statistical programming software `R` [@citeR] along with the help `tidyverse` [@citeTidyverse], `knitr` [@citeKnitr], `ggplot2` [@citeGgplot], `here` [@citeHere], `dplyr` [@citeDplyr], `rstanarm` [@citeRstanarm], `arrow` [@citeArrow], `broom.mixed` [@citeBroomMixed], `modelsummary` [@citeModelSummary] and `kableExtra` [@citeKableExtra].

## Analysis Dataset
The raw datasets were obtained from Alex Cookson's datasets (link). I chose the ones cleaned for Himalayan expeditions. Alex got his datasets from The Himalayan Database (link). 

The Himalayan Database is a compilation of records for all expeditions that have climbed in the Nepal Himalaya. The database is based on the expedition archives of Elizabeth Hawley, a longtime journalist based in Kathmandu, and it is supplemented by information gathered from books, alpine journals and correspondence with Himalayan climbers.

The original database currently covers all expeditions from 1905 through Spring-Summer 2023 to the most significant mountaineering peaks in Nepal. Also included are expeditions to both sides of border peaks such as Everest, Cho Oyu, Makalu and Kangchenjunga as well as to some smaller border peaks. Data on expeditions to trekking peaks are included for early attempts, first ascents and major accidents. The updates to this database are published bi-annually. 

My dataset derived from Alex's contains the entries from 1905 through Spring 2019.

The three datasets I considered included information about all peaks, all expeditions on those peaks and all members on those expeditions. The data from these three datasets are combined to form the main analysis dataset. 
A person becomes an entry in my analysis dataset if, between 1905 and Spring 2019, they attempted to climb any one of the many Himalayan peaks in Nepal. It also included expeditions to both sides of border peaks as mentioned before. 

Among the overall range of variables available, I chose the following to be included in the analysis dataset. 

- `Height` is the height range in which the peak's height in metres falls. This is for the peak the person in the current entry is on an expedition for. The categories for this are 5400 - 5749, 5750 - 6099, 6100 - 6449, 6450 - 6799, 6800 - 7149, 7150 - 7499, 7500 - 7849, 7850 - 8199, 8200 - 8549 and 8550 - 8900.
- `Seasons` is the season the expedition is embarked in. This takes on either of the four values: Autumn, Spring, Winter, Summer.
- `Sex` is the sex reported by the expedition member and it is either male or female.
- `Age` is the age group in which the expedition member fell in at the time of the expedition. Depending on the best available data, this could be as of the summit date, the date of death, or the date of arrival at basecamp. The different categories for this are Under 18,19-30, 31-40, 41-50, 51-60, 61-70, 71-80 and 81-90.
- `Success`represents whether the person's expedition resulted in a successful summit.
- `Solo` represents whether the person attempted a solo ascent.
- `Died` represents whether the person died during the expedition.

```{r}
#| echo: false
#| warning: false
#| message: false
#| fig-cap: Counts for the variables of interest
#| fig-subcap: ["Sex", "Solo Status", "Age", "Seasons", "Height of the Peak"]
#| label: fig-counts
#| layout-ncol: 2

plot_bar <- function(data, x, x_label) {
  if (x == "age_range") {
    custom_order <- c("Under 18", "19-30", "31-40", "41-50", "51-60", "61-70", "71-80", "81-90")
    data[[x]] <- factor(data[[x]], levels = custom_order)
  }

  ggplot(data, aes_string(x = x)) +
    geom_bar(fill = "lightblue") +
    labs(x = x_label, y = "Count") +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
}

plot_bar(analysis_data, "sex", "Sex")
plot_bar(analysis_data, "solo", "Solo Status")
plot_bar(analysis_data, "age_range", "Age")
plot_bar(analysis_data, "seasons", "Season")
plot_bar(analysis_data, "height_range", "Height of the Peak")
```

@fig-counts shows the counts for different variables we are considering to model. We see that there are significantly higher men than women. This shows the existence of a gender imbalance skewed towards men in mountaineering in the Himalayas. We also see other trends like most of the expedition members choose to not do solo ascents, most of the members fall in the middle-aged range and the peak expedition seasons are the more pleasant autumn and spring compared to the extreme seasons like winter and summer. These difference in counts need to be kept in mind when analysing success proportions.

```{r}
#| echo: false
#| warning: false
#| message: false
#| fig-cap: Proportions for the variables of interest and the outcome of their expedition
#| fig-subcap: ["Sex", "Solo Status", "Age", "Seasons", "Height of the Peak"]
#| label: fig-proportions
#| layout-ncol: 2

library(tidyr)

# Define a function to create the plot for each variable
create_plot <- function(data, x_var, x_label) {
  custom_order <- c("Under 18", "19-30", "31-40", "41-50", "51-60", "61-70", "71-80", "81-90")

  # Create a dataframe with all possible combinations of x_var, success, and died
  all_combinations <- expand.grid(
    x_var = unique(data[[x_var]]),
    success = c(TRUE, FALSE),
    died = c(TRUE, FALSE)
  )

  # Join the original data with all_combinations to fill in missing combinations
  plot_data <- all_combinations %>%
    left_join(data, by = c(x_var = x_var, success = "success", died = "died")) %>%
    group_by(x_var, success, died) %>%
    summarise(count = n(), .groups = "drop") %>%
    group_by(x_var) %>%
    mutate(proportion = count / sum(count)) %>%
    filter(success | died)

  # If x_var is "age_range", convert it to a factor with custom order
  if (x_var == "age_range") {
    plot_data$x_var <- factor(plot_data$x_var, levels = custom_order)
  }

  plot_data$success <- factor(plot_data$success, levels = c(TRUE, FALSE))

  p <- ggplot(plot_data, aes(x = x_var, y = proportion, fill = factor(success))) +
    geom_bar(stat = "identity", position = "dodge") +
    scale_fill_manual(
      values = c("TRUE" = "green", "FALSE" = "red"),
      labels = c("Success", "Died"),
      name = "Outcome"
    ) +
    labs(x = x_label, y = "Proportion") +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))

  return(p)
}

# Create plots for each variable
create_plot(analysis_data, "sex", "Sex")
create_plot(analysis_data, "solo", "Solo Status")
create_plot(analysis_data, "age_range", "Age")
create_plot(analysis_data, "seasons", "Season")
create_plot(analysis_data, "height_range", "Height of the Peak")
```

@fig-proportions shows the proportion of expedition members who has a successful outcome or died during their expedition. For sex, we see more men had successful expeditions compared to women. This is interesting keeping in the mind the vast difference in the counts of these two sexes going on expeditions. It might spark an interesting discussion into the gender imbalance in mountaineering. Additionally, we see most of the people who go on expeditions solo have more deaths which might explain the difference in the counts of people attempting solo ascent versus not attempting a solo ascent which was observed earlier. Some other trend we observe are that success rates decline with age and winter season contributes to the most deaths. The success and death proportions based on the height are very varied and do not follow a specific trend. This goes to show that just the height of the peak alone doesn't define the probability of having a successful summit but there are other factors which go into it.

\newpage

# Model {#sec-model}
I used a Bayesian Logistic Regression model to find the probability that someone will successfully summit the Himalayan peak they are on the expedition for. Logistic regression is a method used for binary classification to predict the probability of a categorical dependent variable. 

My model will be based on five independent demographic variables: `height of the peak`, `sex`, `age`, `seasons` and `solo` and the dependent variable will be `success`.

The logistic regression model I will be using is:
\begin{equation}
\log\left(\frac{\hat{p}}{1 - \hat{p}}\right) = \beta_0 + \beta_1 \times \text{height} + \beta_2 \times \text{sex} + \beta_3 \times \text{age} + \beta_4 \times \text{seasons} + \beta_5 \times \text{solo} 
\end{equation}

$$
\begin{aligned}
\beta_0 & \sim \mbox{Normal}(0, 2.5)\\
\beta_1 & \sim \mbox{Normal}(0, 2.5)\\
\beta_2 & \sim \mbox{Normal}(0, 2.5)\\
\beta_3 & \sim \mbox{Normal}(0, 2.5)\\
\beta_4 & \sim \mbox{Normal}(0, 2.5)\\
\beta_5 & \sim \mbox{Normal}(0, 2.5)
\end{aligned}
$$
where,

- $\hat{p}$ represents the probability that someone will successfully summit the peak they are on the expedition for.
- $\beta_0$ represents the intercept term of this logistical regression. It is the probability that someone will successfully summit the peak they are on the expedition for if the predictors' values are zero
- $\beta_1$ is the coefficient corresponding to height of the peak
- $\beta_2$ is the coefficient corresponding to sex of the person
- $\beta_3$ is the coefficients corresponding to age of the person
- $\beta_4$ is the coefficients corresponding to seasons of the person
- $\beta_5$ is the coefficients corresponding to if the person is attempting the summit alone

In my model, normal priors with a mean of 0 and a standard deviation of 2.5 are used for both the coefficients and the intercept. Setting the mean of the priors to 0 implies that there is no expectation of a particular direction or magnitude for the coefficients or intercept. I chose this as I have no expectation of the same. The standard deviation of 2.5 reflects the uncertainty or variability in the prior beliefs. I chose a moderately wide prior to allow for a reasonable amount of uncertainty. 

The chosen priors allow the data to largely determine the posterior distribution as they are relatively non-informative. They don't heavily influence the results unless the data provide strong evidence to the contrary.

The use of moderately wide priors can also help regularize the model, preventing overfitting and providing more stable estimates, particularly when dealing with limited data.

```{r}
#| echo: false
#| warning: false
#| message: false
#| label: tbl-model-coefficients
#| tbl-cap: Summary of the model
#
# # Create model summary
# model_summary <- modelsummary(expeditions_model)

# Extract coefficients
coefficients <- broom::tidy(expeditions_model, conf.int = TRUE)
coefficients |> kable(digits = 2)
```
@tbl-model-coefficients shows the coefficients for my Bayesian model along with the standard error and the 95% credible interval. The standard error (SE) is a measure of the precision with which a sample statistic estimates a population parameter. It quantifies the variability of sample statistics around the population parameter. A 95% credible interval means that there is a 95% probability that the true parameter lies within the interval, given the observed data and the model assumptions. 

# Results {#sec-results}

```{r}
#| echo: false
#| warning: false
#| message: false
#| label: fig-model-coefficients
#| fig-cap: Coefficients of the model

coefficients <- coefficients[coefficients$term != "age_range81-90", ]

ggplot(coefficients, aes(x = estimate, y = term)) +
  geom_point() + # Coefficient points
  geom_errorbarh(aes(xmin = conf.low, xmax = conf.high)) + # Confidence/Credible interval bars
  geom_vline(xintercept = 0, linetype = "dashed", color = "red") + # Add zero line
  labs(x = "Coefficient Estimate", y = "Predictor Variable") + # Axis labels
  theme_minimal() # Minimal theme for better readability
``` 

@fig-model-coefficients illustrates the coefficients and their associated 95% credible intervals for the predictor variables in the Bayesian model. Each point represents the estimated coefficient for a predictor variable, while the horizontal lines depict the credible interval around the estimate. Variables with coefficients to the right of zero indicate a positive association with the outcome variable, suggesting that an increase in the predictor variable corresponds to an increase in the outcome variable. Conversely, coefficients to the left of zero indicate a negative association, implying that an increase in the predictor variable is associated with a decrease in the outcome variable. These insights can help in understanding the direction and magnitude of the relationships between predictor variables and the outcome in the Bayesian model. I removed the coefficient for age_range81-90 which according to @tbl-model-coefficients was very small leading to all other coefficients being uninterpretable in the plot.

We see that the males have a slightly higher success probability compared to females. We also notice how expeditions in Summer and Winter have lesser success probability than Autumn whereas Spring has higher success probability than it. Additionally, we notice the success probabilities getting lower with increase in age.

```{r}
#| echo: false
#| warning: false
#| message: false
#| label: fig-age-sex
#| fig-cap: Predicted Success Probability by Age and Sex

# Define custom order for age_range levels
custom_order <- c("Under 18", "19-30", "31-40", "41-50", "51-60", "61-70", "71-80", "81-90")

# Convert age_range to factor with custom order
predictions$age_range <- factor(predictions$age_range, levels = custom_order)

ggplot(predictions, aes(x = age_range, y = success_probability, fill = sex)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(
    x = "Age",
    y = "Success Probability"
  ) +
  facet_grid(sex ~ .) +
  theme_minimal()
```
@fig-age-sex shows the predicted success probability according the the age and sex of the expedition member. We notice that the success probabilities over all ages tend to be slightly higher in males compared to females, just as we saw in @fig-model-coefficients. But, when combined with age we see there differences are not constant. We see that the difference in the success probabilities for people under 50 are very close to each other but for people aged 51 or above the difference is much larger. The success probabilities are pretty high, crossing 0.8 for younger individuals but starts declining with increase in age. The steep decline in category 81-90 might stem from the significant less number of expedition members in that age group leading to a less varied result.

```{r}
#| echo: false
#| warning: false
#| message: false
#| label: fig-height-seasons
#| fig-cap: Predicted Success Probability by Height of the Peak and Seasons

ggplot(predictions, aes(x = height_range, y = success_probability, fill = seasons)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(
    x = "Height of the Peak",
    y = "Success Probability"
  ) +
  facet_grid(seasons ~ .) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```
@fig-height-seasons shows the predicted success probability according the the height of the peak being ascended and the season of expedition. We notice that the success probabilities are pretty high for shorter mountain ranges and become lesser with increase in height. This might have to do with the fact that less higher peaks could be comparatively easier to summit. This, however, cannot be established as the trend as we see a non-pattern being followed for heights 6800 metres and above. We see that winter season expeditions have lower success probabilities, probably owning to the extreme cold conditions at higher altitudes. We also notice interesting trend as an interaction of these two factors. One such trend would be the success probabilities during different seasons for peaks between 5400 metres and 5749 metres are all comparatively closer to each other than compared to peaks between 7500 metres and 7849 metres in height. All seasons' success probabilities for peaks between 5400 metres and 5749 metres fall between 0.85 to 0.9 whereas for for peaks between 7500 metres and 7848 metres, the success probabilities go from around 0.35 in Winter to around 0.6 in Autumn or Spring.

# Discussion {#sec-discussion}
1) What is done in this paper? 
2) What is something that we learn about the world?

## Weaknesses and Limitations

## Future Directions

# Appendix

## Cleaning
For the analysis data, the cleaning steps I took were:

1. Initial merging: The raw data from the expeditions and members datasets is merged based on a common identifier, expedition_id, consolidating information about expedition participants.

2. Column selection and renaming: Irrelevant columns are removed from the merged dataset, and the remaining columns (`peak_id.x`, `season.x`, `sex`, `age`, `success`, `solo`, `died`) are selected for further analysis. Additionally, column `peak_id.x` is renamed to `peak_id`.

3. Secondary merging: The cleaned `expeditions` dataset is merged with the `peaks` dataset based on a common identifier, `peak_id`, to incorporate information about the height of each peak climbed during expeditions.

4. Filtering out incomplete data: Rows with missing values for key variables such as `sex` or `age` are filtered out to ensure the integrity of the dataset.

5. New ranges: Height range categories are created based on predefined ranges in meters: 5400-5749, 5750-6099, 6100-6449, 6450-6799, 6800-7149, 7150-7499, 7500-7849, 7850-8199, 8200-8549, and 8550-8900. Age range categories are defined as follows: Under 18, 19-30, 31-40, 41-50, 51-60, 61-70, 71-80, 81-90, and 91 or older.

5. Final dataset creation: `season.x` is renamed to `seasons`. and then the resulting dataset is further refined to include only relevant columns (`height_range`, `seasons`, `sex`, `age_range`, `success`, `solo`, `died`).

## Analysis dataset
Here is a glimpse of the dataset used for analysis

```{r}
#| echo: false
#| warning: false
#| message: false
#| label: tbl-survey
#| tbl-cap: Analysis dataset
#|
head(analysis_data) %>%
  kable(digits = 2)
```

## Model summary

## Hello
```{r}
#| label: fig-post_dist
#| fig-cap: Posterior distribution for logistic regression model
#| echo: false
#| warning: false
#| message: false

library(bayesplot)

pp_check(expeditions_model) +
  theme(legend.position = "bottom")
```

# References
